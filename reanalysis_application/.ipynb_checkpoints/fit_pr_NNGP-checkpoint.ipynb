{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "from jax import vmap, grad, jit, random\n",
    "from jax.config import config\n",
    "from jax.experimental import optimizers\n",
    "import jax.numpy as jnp\n",
    "from jax.tree_util import tree_map, tree_flatten, tree_unflatten, tree_leaves\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from skimage.restoration import estimate_sigma\n",
    "from skimage.transform import resize\n",
    "\n",
    "### CRPS\n",
    "import properscoring as ps\n",
    "\n",
    "### SSIM and PSNR\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "plt.style.use('default')\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import colors\n",
    "from cartopy import config\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# netCDF\n",
    "import netCDF4 as nc\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model init\n",
    "\n",
    "def nngp_params(key, depth = 1):\n",
    "\n",
    "    subkeys = random.split(key, 3 + 2 * (depth - 1))\n",
    "\n",
    "    base_layer = jnp.array([random.uniform(subkeys[0], minval = 0.75, maxval = 1.25), \n",
    "                            random.uniform(subkeys[1], minval = 0.1, maxval = 0.5),\n",
    "                            random.uniform(subkeys[2], minval = 2, maxval = 3)])\n",
    "    base_layer = [tuple(base_layer)]\n",
    "\n",
    "    return base_layer\n",
    "parallel_nngp_params = vmap(nngp_params, in_axes=(0, None))\n",
    "\n",
    "\n",
    "def random_params(key, depth):\n",
    "    nngp_par = nngp_params(key, depth)\n",
    "    trend_par = trend_params(key)\n",
    "    \n",
    "    return [nngp_par, trend_par]\n",
    "parallel_params = vmap(random_params, in_axes=(0, None))\n",
    "\n",
    "@jit\n",
    "def random_init(params):\n",
    "    return opt_init(params)\n",
    "parallel_init = vmap(random_init)\n",
    "\n",
    "@jit\n",
    "def param_abs(x):\n",
    "    return jnp.abs(x)\n",
    "\n",
    "@jit\n",
    "def param_select(param_list, i):\n",
    "    return tree_map(lambda x: x[i], param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model specification\n",
    "\n",
    "depth = 10\n",
    "\n",
    "## nngp functions\n",
    "def nngp_kernel(params, x, y):\n",
    "    x = jnp.array(x)\n",
    "    y = jnp.array(y)\n",
    "    \n",
    "    kxx = params[0][1] + params[0][0] * (jnp.dot(x, x.T) / x.shape[0])\n",
    "    kyy = params[0][1] + params[0][0] * (jnp.dot(y, y.T) / x.shape[0])\n",
    "    kxy = params[0][1] + params[0][0] * (jnp.dot(x, y.T) / x.shape[0])\n",
    "    \n",
    "    for i in range(depth):\n",
    "        \n",
    "        ## kxy\n",
    "        cor = jnp.clip(kxy / jnp.sqrt(kxx * kyy), -1.0 + 1e-16, 1.0 - 1e-16)\n",
    "        theta = jnp.arccos(cor)\n",
    "        trig = jnp.sin(theta) + (math.pi - theta) * jnp.cos(theta)\n",
    "        kxy = params[0][1] + (params[0][0] / (2 * math.pi)) * jnp.sqrt(kxx * kyy) * trig\n",
    "                \n",
    "        ## kxx\n",
    "        kxx = params[0][1] + (params[0][0] / 2) * kxx\n",
    "    \n",
    "        ## kyy\n",
    "        kyy = params[0][1] + (params[0][0] / 2) * kyy\n",
    "        \n",
    "    return kxy\n",
    "\n",
    "nngp_kernel = jit(nngp_kernel)\n",
    "nngp_cov = jit(vmap(vmap(nngp_kernel, (None, None, 0)), (None, 0, None)))\n",
    "nngp_var = jit(vmap(nngp_kernel, (None, 0, 0)))\n",
    "\n",
    "\n",
    "def nngp_predict(params, xtest, xtrain, ytrain):\n",
    "    n, p = ytrain.shape\n",
    "        \n",
    "    k_DD0 = nngp_cov(params, xtrain, xtrain)\n",
    "    k_DD0 += jnp.diag(jnp.repeat(params[0][2], n))\n",
    "    prec0 = jnp.linalg.inv(k_DD0)\n",
    "    \n",
    "    k_xD0 = nngp_cov(params, xtest, xtrain)\n",
    "    \n",
    "    proj0 = jnp.matmul(k_xD0, prec0)\n",
    "    return jnp.matmul(proj0, ytrain)\n",
    "nngp_predict = jit(nngp_predict)\n",
    "\n",
    "\n",
    "def nngp_dist(params, xtest, xtrain, ytrain):\n",
    "    n, p = ytrain.shape\n",
    "        \n",
    "    k_DD0 = nngp_cov(params, xtrain, xtrain)\n",
    "    k_DD0 += jnp.diag(jnp.repeat(params[0][2], n))\n",
    "    prec0 = jnp.linalg.inv(k_DD0)\n",
    "    \n",
    "    k_xD0 = nngp_cov(params, xtest, xtrain)\n",
    "    proj0 = jnp.matmul(k_xD0, prec0)\n",
    "    \n",
    "    mu = jnp.matmul(proj0, ytrain)\n",
    "    \n",
    "    k_xx = nngp_var(params, xtest, xtest)\n",
    "    sig = k_xx - jnp.sum(proj0 * k_xD0, axis = 1)\n",
    "    \n",
    "    return mu, sig\n",
    "nngp_dist = jit(nngp_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### loss functions\n",
    "\n",
    "def compute_lr(pgrad, scale = 2):\n",
    "    leaves = jnp.array(tree_leaves(pgrad))\n",
    "    lrs = 10**(-jnp.floor(jnp.log10(jnp.abs(leaves))) - scale)\n",
    "    return lrs\n",
    "\n",
    "def weighted_mse(k_inv, ytrain):\n",
    "    return jnp.matmul(jnp.matmul(ytrain.T, k_inv), ytrain)\n",
    "weighted_mse = jit(vmap(weighted_mse, (None, 1)))\n",
    "\n",
    "\n",
    "def nll_loss(params, xtrain, ytrain):\n",
    "    n, p = ytrain.shape\n",
    "\n",
    "    k = nngp_cov(params, xtrain, xtrain)\n",
    "    k += jnp.diag(jnp.repeat(params[0][2], n))\n",
    "    k_inv = jnp.linalg.inv(k)\n",
    "    \n",
    "    mse = jnp.sum(weighted_mse(k_inv, ytrain))\n",
    "    pen = p * jnp.linalg.slogdet(k)[1]\n",
    "    nor = p * jnp.log(2 * math.pi)\n",
    "\n",
    "    return (mse + pen + nor) / (2 * p)\n",
    "\n",
    "grad_loss = jit(grad(nll_loss))\n",
    "\n",
    "\n",
    "def gradient_step(params, xtrain, ytrain):\n",
    "        \n",
    "    param, tdef = tree_flatten(params)\n",
    "    pgrad = tree_flatten(grad_loss(params, xtrain, ytrain))[0]\n",
    "    \n",
    "    lrs = compute_lr(pgrad, 2)\n",
    "    param = [a - lr * b for a, b, lr in zip(tree_leaves(param), pgrad, lrs)]\n",
    "    \n",
    "#     lr = 1e-3\n",
    "#     param = [a - lr * b for a, b in zip(tree_leaves(param), pgrad)]\n",
    "    params = tree_unflatten(tdef, param)\n",
    "    params = tree_map(param_abs, params)\n",
    "    return params\n",
    "gradient_step = jit(gradient_step)\n",
    "# parallel_gradient_step = vmap(gradient_step, in_axes = (0, None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhist = pickle.load(open('../data/saved/xhist_pr.pkl', 'rb'))\n",
    "xrcp = pickle.load(open('../data/saved/xrcp_pr.pkl', 'rb'))\n",
    "\n",
    "reanalysis = np.load('../data/saved/pr_obs.npz.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 1011, 9, 789, 16, 721, 1440)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntrain = xhist[0].shape[0]\n",
    "nval = 81-72\n",
    "\n",
    "nfit = ntrain + nval\n",
    "\n",
    "ntest = xrcp[0].shape[0] - nval\n",
    "nmod = len(xhist)\n",
    "nlat = reanalysis.shape[1]\n",
    "nlon = reanalysis.shape[2]\n",
    "\n",
    "ntrain, ntest, nval, nfit, nmod, nlat, nlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86526abe2894ac8bffc2e1f31ef5386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### construct training set\n",
    "xtrain = []\n",
    "for m2 in trange(nmod):\n",
    "    x1 = xhist[m2].reshape(ntrain, -1)\n",
    "    x2 = xrcp[m2][0:nval].reshape(nval, -1)\n",
    "    xtrain.append(np.vstack([x1, x2]))\n",
    "\n",
    "xmean = np.array([np.mean(f, axis = 1) for f in xtrain])\n",
    "xtrain = jnp.hstack(xtrain)\n",
    "\n",
    "ytrain = reanalysis[0:nfit].reshape(nfit, -1)\n",
    "ymean = jnp.mean(ytrain, axis = 1)\n",
    "\n",
    "x = jnp.vstack([xmean]).T\n",
    "beta = jnp.linalg.inv(x.T @ x) @ x.T @ ymean\n",
    "ytrain = ytrain - (x @ beta)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96886ab39db8442ebe86fccb3a638884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## randomize ensemble init\n",
    "key = random.PRNGKey(1023)\n",
    "params = nngp_params(key, depth)\n",
    "\n",
    "iterations = 300\n",
    "\n",
    "## fit ensemble\n",
    "for i in trange(iterations, leave = True):\n",
    "    params = gradient_step(params, xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./pr_model_coef/nngp_params', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_int = 70\n",
    "xtest = []\n",
    "for m2 in range(nmod):\n",
    "    xtest.append(xrcp[m2][nval:(nval+pred_int)].reshape(pred_int, -1))\n",
    "    \n",
    "xmean = np.array([np.mean(f, axis = 1) for f in xtest])\n",
    "xtest = jnp.hstack(xtest)\n",
    "x = jnp.vstack([xmean]).T\n",
    "\n",
    "ytest = np.load('../data/saved/t2m_obs.npy', mmap_mode = 'r')[nfit:(nfit + pred_int),]\n",
    "ytest = np.array(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = nngp_predict(params, xtest, xtrain, ytrain).reshape(-1, nlat, nlon)\n",
    "yhat += (x @ beta)[:,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.40490453, dtype=float64)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = np.cos(np.linspace(math.pi/2, -math.pi/2, nlat))\n",
    "scale /= np.mean(scale)\n",
    "\n",
    "np.mean((ytest - yhat)**2 * scale[None,:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('./model_coef/nngp_params', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "nngp = np.load('./predictions/nngp_pred.npy', mmap_mode = 'r')[0:pred_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39993924367429073"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((ytest_asia - nngp[:,y1:y2,x1:x2])**2 * scale[None,:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
