{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "from functools import partial\n",
    "from jax import vmap, grad, jit, random\n",
    "from jax.config import config\n",
    "# from jax.experimental import optimizers\n",
    "import jax.numpy as jnp\n",
    "from jax.tree_util import tree_map, tree_flatten, tree_unflatten, tree_leaves\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from skimage.restoration import estimate_sigma\n",
    "from skimage.transform import resize\n",
    "\n",
    "# netCDF\n",
    "import netCDF4 as nc\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model init\n",
    "\n",
    "def exp_params(key):\n",
    "\n",
    "    subkeys = random.split(key, 3)\n",
    "\n",
    "    base_layer = jnp.array([random.uniform(subkeys[0], minval = 3.5, maxval = 4.5),\n",
    "                            random.uniform(subkeys[1], minval = 8, maxval = 12),\n",
    "                            random.uniform(subkeys[2], minval = 1, maxval = 5)])\n",
    "    base_layer = [tuple(base_layer)]\n",
    "\n",
    "    return base_layer\n",
    "\n",
    "@jit\n",
    "def random_init(params):\n",
    "    return opt_init(params)\n",
    "parallel_init = vmap(random_init)\n",
    "\n",
    "@jit\n",
    "def param_abs(x):\n",
    "    return jnp.abs(x)\n",
    "\n",
    "@jit\n",
    "def param_select(param_list, i):\n",
    "    return tree_map(lambda x: x[i], param_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model specification\n",
    "\n",
    "## nngp functions\n",
    "def exp_kernel(params, x, y):\n",
    "    x = jnp.array(x)\n",
    "    y = jnp.array(y)\n",
    "    \n",
    "    return params[0][0] * jnp.exp(-jnp.sqrt(jnp.mean((x - y)**2)) / params[0][1])\n",
    "\n",
    "exp_kernel = jit(exp_kernel)\n",
    "exp_cov = jit(vmap(vmap(exp_kernel, (None, None, 0)), (None, 0, None)))\n",
    "exp_var = jit(vmap(exp_kernel, (None, 0, 0)))\n",
    "\n",
    "def exp_predict(params, xtest, xtrain, ytrain):\n",
    "    n, p = ytrain.shape\n",
    "        \n",
    "    k_DD0 = exp_cov(params, xtrain, xtrain)\n",
    "    k_DD0 += jnp.diag(jnp.repeat(params[0][2], n))\n",
    "    prec0 = jnp.linalg.inv(k_DD0)\n",
    "    \n",
    "    k_xD0 = exp_cov(params, xtest, xtrain)\n",
    "    \n",
    "    proj0 = jnp.matmul(k_xD0, prec0)\n",
    "    return jnp.matmul(proj0, ytrain)\n",
    "exp_predict = jit(exp_predict)\n",
    "\n",
    "\n",
    "def exp_dist(params, xtest, xtrain, ytrain):\n",
    "    n, p = ytrain.shape\n",
    "        \n",
    "    k_DD0 = exp_cov(params, xtrain, xtrain)\n",
    "    k_DD0 += jnp.diag(jnp.repeat(params[0][2], n))\n",
    "    prec0 = jnp.linalg.inv(k_DD0)\n",
    "    \n",
    "    k_xD0 = exp_cov(params, xtest, xtrain)\n",
    "    proj0 = jnp.matmul(k_xD0, prec0)\n",
    "    \n",
    "    mu = jnp.matmul(proj0, ytrain)\n",
    "    \n",
    "    k_xx = exp_var(params, xtest, xtest)\n",
    "    sig = k_xx - jnp.sum(proj0 * k_xD0, axis = 1)\n",
    "    \n",
    "    return mu, sig\n",
    "exp_dist = jit(exp_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model specification\n",
    "\n",
    "## nngp functions\n",
    "def se_kernel(params, x, y):\n",
    "    x = jnp.array(x)\n",
    "    y = jnp.array(y)\n",
    "    \n",
    "    return params[0][0] * jnp.exp(-jnp.mean((x - y)**2) / params[0][1]**2)\n",
    "\n",
    "se_kernel = jit(se_kernel)\n",
    "se_cov = jit(vmap(vmap(se_kernel, (None, None, 0)), (None, 0, None)))\n",
    "se_var = jit(vmap(se_kernel, (None, 0, 0)))\n",
    "\n",
    "\n",
    "def se_predict(params, xtest, xtrain, ytrain):\n",
    "    n, p = ytrain.shape\n",
    "        \n",
    "    k_DD0 = se_cov(params, xtrain, xtrain)\n",
    "    k_DD0 += jnp.diag(jnp.repeat(params[0][2], n))\n",
    "    prec0 = jnp.linalg.inv(k_DD0)\n",
    "    \n",
    "    k_xD0 = se_cov(params, xtest, xtrain)\n",
    "    \n",
    "    proj0 = jnp.matmul(k_xD0, prec0)\n",
    "    return jnp.matmul(proj0, ytrain)\n",
    "se_predict = jit(se_predict)\n",
    "\n",
    "\n",
    "def se_dist(params, xtest, xtrain, ytrain):\n",
    "    n, p = ytrain.shape\n",
    "        \n",
    "    k_DD0 = se_cov(params, xtrain, xtrain)\n",
    "    k_DD0 += jnp.diag(jnp.repeat(params[0][2], n))\n",
    "    prec0 = jnp.linalg.inv(k_DD0)\n",
    "    \n",
    "    k_xD0 = se_cov(params, xtest, xtrain)\n",
    "    proj0 = jnp.matmul(k_xD0, prec0)\n",
    "    \n",
    "    mu = jnp.matmul(proj0, ytrain)\n",
    "    \n",
    "    k_xx = se_var(params, xtest, xtest)\n",
    "    sig = k_xx - jnp.sum(proj0 * k_xD0, axis = 1)\n",
    "    \n",
    "    return mu, sig\n",
    "se_dist = jit(se_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### loss functions\n",
    "\n",
    "def compute_lr(pgrad, scale = 2):\n",
    "    leaves = jnp.array(tree_leaves(pgrad))\n",
    "    lrs = 10**(-jnp.floor(jnp.log10(jnp.abs(leaves))) - scale)\n",
    "    return lrs\n",
    "\n",
    "def weighted_mse(k_inv, ytrain):\n",
    "    return jnp.matmul(jnp.matmul(ytrain.T, k_inv), ytrain)\n",
    "weighted_mse = jit(vmap(weighted_mse, (None, 1)))\n",
    "\n",
    "\n",
    "def nll_loss_exp(params, xtrain, ytrain):\n",
    "    n, p = ytrain.shape\n",
    "\n",
    "    k = exp_cov(params, xtrain, xtrain)\n",
    "    k += jnp.diag(jnp.repeat(params[0][2], n))\n",
    "    k_inv = jnp.linalg.inv(k)\n",
    "    \n",
    "    mse = jnp.sum(weighted_mse(k_inv, ytrain))\n",
    "    pen = p * jnp.linalg.slogdet(k)[1]\n",
    "    nor = p * jnp.log(2 * math.pi)\n",
    "\n",
    "    return (mse + pen + nor) / (2 * p)\n",
    "nll_loss_exp = jit(nll_loss_exp)\n",
    "grad_loss_exp = jit(grad(nll_loss_exp))\n",
    "\n",
    "def nll_loss_se(params, xtrain, ytrain):\n",
    "    n, p = ytrain.shape\n",
    "\n",
    "    k = se_cov(params, xtrain, xtrain)\n",
    "    k += jnp.diag(jnp.repeat(params[0][2], n))\n",
    "    k_inv = jnp.linalg.inv(k)\n",
    "    \n",
    "    mse = jnp.sum(weighted_mse(k_inv, ytrain))\n",
    "    pen = p * jnp.linalg.slogdet(k)[1]\n",
    "    nor = p * jnp.log(2 * math.pi)\n",
    "\n",
    "    return (mse + pen + nor) / (2 * p)\n",
    "nll_loss_se = jit(nll_loss_se)\n",
    "grad_loss_se = jit(grad(nll_loss_se))\n",
    "\n",
    "def gradient_step_exp(params, xtrain, ytrain):\n",
    "        \n",
    "    param, tdef = tree_flatten(params)\n",
    "    pgrad = tree_flatten(grad_loss_exp(params, xtrain, ytrain))[0]\n",
    "    \n",
    "    lrs = compute_lr(pgrad, 2)\n",
    "    param = [a - lr * b for a, b, lr in zip(tree_leaves(param), pgrad, lrs)]\n",
    "    \n",
    "    params = tree_unflatten(tdef, param)\n",
    "    params = tree_map(param_abs, params)\n",
    "    return params\n",
    "gradient_step_exp = jit(gradient_step_exp)\n",
    "\n",
    "\n",
    "def gradient_step_sqe(params, xtrain, ytrain):\n",
    "        \n",
    "    param, tdef = tree_flatten(params)\n",
    "    pgrad = tree_flatten(grad_loss_se(params, xtrain, ytrain))[0]\n",
    "    \n",
    "    lrs = compute_lr(pgrad, 2)\n",
    "    param = [a - lr * b for a, b, lr in zip(tree_leaves(param), pgrad, lrs)]\n",
    "    \n",
    "    params = tree_unflatten(tdef, param)\n",
    "    params = tree_map(param_abs, params)\n",
    "    return params\n",
    "gradient_step_sqe = jit(gradient_step_sqe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhist = pickle.load(open('../submit/data/saved/xhist_pr.pkl', 'rb'))\n",
    "xrcp = pickle.load(open('../submit/data/saved/xrcp_pr.pkl', 'rb'))\n",
    "\n",
    "nval = 72\n",
    "ntest = len(xrcp[0])\n",
    "# ntest = 72 + 336\n",
    "nmod = len(xhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5866dc8f184dfba7572f7e3b4b2565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### run experiments\n",
    "nmod = len(xhist)\n",
    "ntrain = xhist[0].shape[0]\n",
    "ntest = xrcp[0].shape[0]\n",
    "\n",
    "\n",
    "for m1 in trange(nmod):\n",
    "\n",
    "    _, nlat, nlon = xhist[m1].shape\n",
    "\n",
    "    #### construct training set\n",
    "    xtrain = []\n",
    "    for m2 in trange(nmod, leave = False):\n",
    "        if m1 != m2:\n",
    "            x1 = xhist[m2].reshape(ntrain, -1)\n",
    "            x2 = xrcp[m2][0:nval].reshape(nval, -1)\n",
    "\n",
    "            xtrain.append(np.vstack([x1, x2]))\n",
    "\n",
    "    xmean = np.array([np.mean(f, axis = 1) for f in xtrain])\n",
    "    xtrain = jnp.hstack(xtrain)\n",
    "\n",
    "    y1 = xhist[m1].reshape(ntrain, -1)\n",
    "    y2 = xrcp[m1][0:nval].reshape(nval, -1)\n",
    "\n",
    "    ytrain = jnp.array(np.vstack([y1, y2]))\n",
    "    ymean = jnp.mean(ytrain, axis = 1)\n",
    "\n",
    "    x = jnp.vstack([xmean]).T\n",
    "    beta = jnp.linalg.inv(x.T @ x) @ x.T @ ymean\n",
    "    ytrain = ytrain - (x @ beta)[:,None]\n",
    "\n",
    "\n",
    "    #### test\n",
    "    xtest = []\n",
    "    for m2 in range(nmod):\n",
    "        if m1 != m2:\n",
    "            xtest.append(xrcp[m2][nval:ntest].reshape(ntest-nval, -1))\n",
    "\n",
    "     ## center and join data\n",
    "    xmean = np.array([np.mean(f, axis = 1) for f in xtest])\n",
    "    xtest = jnp.hstack(xtest)\n",
    "    ytest = np.array(xrcp[m1][nval:ntest])\n",
    "    x = jnp.vstack([xmean]).T\n",
    "\n",
    "\n",
    "    ## randomize ensemble init\n",
    "    key = random.PRNGKey(1023)\n",
    "    params_exp = exp_params(key)\n",
    "    params_sqe = exp_params(key)\n",
    "\n",
    "    ## fit ensemble\n",
    "    for _ in trange(300):\n",
    "        params_exp = gradient_step_exp(params_exp, xtrain, ytrain)\n",
    "        params_sqe = gradient_step_sqe(params_sqe, xtrain, ytrain) \n",
    "\n",
    "    scale = np.cos(np.linspace(math.pi/2, -math.pi/2, nlat))\n",
    "\n",
    "    exp_hat, exp_predvar = exp_dist(params_exp, xtest, xtrain, ytrain)\n",
    "    exp_hat += (x @ beta)[:,None]\n",
    "    exp_hat = exp_hat.reshape(-1, nlat, nlon)\n",
    "    # exp_hat *= scale[:,]\n",
    "    exp_predvar = np.sqrt(exp_predvar + params_exp[0][2])\n",
    "\n",
    "    sqe_hat, sqe_predvar = se_dist(params_sqe, xtest, xtrain, ytrain)\n",
    "    sqe_hat += (x @ beta)[:,None]\n",
    "    sqe_hat = sqe_hat.reshape(-1, nlat, nlon)\n",
    "    sqe_predvar = np.sqrt(sqe_predvar + params_sqe[0][2])\n",
    "\n",
    "    np.save(f'../submit/experiments/pred/gpr_exp_pr_{m1}.npz', exp_hat)\n",
    "    np.save(f'../submit/experiments/pred/gpr_exp_pr_var_{m1}.npz', exp_predvar)\n",
    "    \n",
    "    np.save(f'../submit/experiments/pred/gpr_se_pr_{m1}.npz', sqe_hat)\n",
    "    np.save(f'../submit/experiments/pred/gpr_se_pr_var_{m1}.npz', sqe_predvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
