{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevorh2/anaconda3/lib/python3.7/site-packages/jax/experimental/optimizers.py:30: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "# from jax\n",
    "import jax\n",
    "from jax import vmap, grad, jit, random, nn\n",
    "from jax.config import config\n",
    "from jax.experimental import optimizers\n",
    "import jax.numpy as jnp\n",
    "from jax.tree_util import tree_map, tree_flatten, tree_unflatten, tree_leaves\n",
    "\n",
    "import haiku as hk\n",
    "import optax\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "from skimage.restoration import estimate_sigma\n",
    "from skimage.transform import resize\n",
    "\n",
    "# netCDF\n",
    "import netCDF4 as nc\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convnet(x):\n",
    "    cnn = hk.Sequential([\n",
    "        hk.Conv2D(128, 3), nn.relu,\n",
    "        hk.Conv2D(64, 3), nn.relu,\n",
    "        hk.Conv2D(32, 3), nn.relu,\n",
    "        hk.Conv2D(1, 3)\n",
    "    ])\n",
    "    return cnn(x)\n",
    "\n",
    "convnet = hk.without_apply_rng(hk.transform(convnet))\n",
    "\n",
    "def rescale(x):\n",
    "    xmin = np.min(x, axis = (1,2))[:,None,None,:]\n",
    "    xmax = np.max(x, axis = (1,2))[:,None,None,:]\n",
    "    return (x - xmin) / (xmax - xmin)\n",
    "\n",
    "def loss(params, x, y):\n",
    "    yhat = convnet.apply(params, x)\n",
    "    return jnp.mean((yhat.squeeze() - y.squeeze())**2)\n",
    "grad_loss = jit(grad(loss))\n",
    "\n",
    "@jit\n",
    "def update(params, opt_state, x, y):\n",
    "    grads = grad_loss(params, x, y)\n",
    "    updates, opt_state = opt_update(grads, opt_state)\n",
    "    return optax.apply_updates(params, updates), opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xhist = pickle.load(open('../data/saved/xhist_tas.pkl', 'rb'))\n",
    "xrcp = pickle.load(open('../data/saved/xrcp_tas.pkl', 'rb'))\n",
    "\n",
    "nval = 72\n",
    "nmod = len(xhist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### run experiments\n",
    "\n",
    "nmod = len(xhist)\n",
    "ntrain = xhist[0].shape[0]\n",
    "ntest = xrcp[0].shape[0]\n",
    "\n",
    "sgpr_list = []\n",
    "\n",
    "for m1 in trange(nmod):\n",
    "\n",
    "    _, nlat, nlon = xhist[m1].shape\n",
    "\n",
    "    #### construct training set\n",
    "    xtrain = []\n",
    "    for m2 in range(nmod):\n",
    "        if m1 != m2:\n",
    "            x1 = xhist[m2]\n",
    "            x2 = xrcp[m2][0:nval]\n",
    "            \n",
    "            xt = np.moveaxis(np.vstack([x1, x2]), 0, 2)\n",
    "            xtrain.append(resize(xt, (nlat, nlon)))\n",
    "        \n",
    "    xtrain = np.moveaxis(np.array(xtrain), (0, 3), (3, 0))\n",
    "    y1 = xhist[m1]\n",
    "    y2 = xrcp[m1][0:nval]\n",
    "    ytrain = jnp.array(np.vstack([y1, y2]))\n",
    "    \n",
    "    \n",
    "    #### construct testing set\n",
    "    xtest = []\n",
    "    for m2 in range(nmod):\n",
    "        if m1 != m2:\n",
    "            x1 = xrcp[m2][nval:ntest]\n",
    "            x1 = np.moveaxis(x1, 0, 2)\n",
    "            xtest.append(resize(x1, (nlat, nlon)))\n",
    "        \n",
    "    xtest = np.moveaxis(np.array(xtest), (0, 3), (3, 0))\n",
    "    ytest = xrcp[m1][nval:ntest]\n",
    "    \n",
    "    \n",
    "    ### train\n",
    "    xtrain = jnp.array(xtrain)\n",
    "    ytrain = jnp.array(ytrain)\n",
    "    \n",
    "    xmean = np.mean(xtrain, axis = (0, 3))\n",
    "    xtrain = xtrain - xmean[None,:,:,None]\n",
    "    ytrain = ytrain - xmean[None,:,:]\n",
    "    xtest = xtest - xmean[None,:,:,None]\n",
    "\n",
    "    key = random.PRNGKey(0)\n",
    "    params = convnet.init(key, xtrain[0:1])\n",
    "\n",
    "    bsize = 128\n",
    "    nepoch = 400\n",
    "    nbatch = int(ytrain.shape[0] / bsize) + 1\n",
    "\n",
    "    ### init opt\n",
    "    opt_init, opt_update = optax.adam(1e-4)\n",
    "    opt_state = opt_init(params)\n",
    "    \n",
    "    for n in trange(nepoch):\n",
    "        for i in trange(nbatch, leave = False):\n",
    "\n",
    "            xi = xtrain[(i*bsize):((i+1)*bsize)]\n",
    "            yi = ytrain[(i*bsize):((i+1)*bsize)]\n",
    "\n",
    "            params, opt_state = update(params, opt_state, xi, yi)\n",
    "            \n",
    "            \n",
    "    bsize = 100\n",
    "    nbatch = int(ytest.shape[0] / bsize) + 1\n",
    "    yhat = []\n",
    "    for i in range(nbatch):\n",
    "        yhat.append(convnet.apply(params, xtest[(i*bsize):((i+1)*bsize)]))\n",
    "\n",
    "    yhat = np.concatenate(yhat).squeeze()\n",
    "    yhat += xmean[None,:,:]\n",
    "    \n",
    "    np.save(f'../experiments/tas_predictions/cnn_tas_{m1}.npz', yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
